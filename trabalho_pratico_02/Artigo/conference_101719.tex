\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage[utf8]{inputenc}
\usepackage{booktabs}
\usepackage{float}
\usepackage[portuguese]{babel}

\makeatletter
\newcommand{\linebreakand}{%
\end{@IEEEauthorhalign}
\hfill\mbox{}\par
\mbox{}\hfill\begin{@IEEEauthorhalign}
}
\makeatother

\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
		T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}

\begin{document}

\title{ANADI - Trabalho Prático 2:\\
Análise de Desempenho De Técnicas de Aprendizagem Automática}

\author{\IEEEauthorblockN{Fábio Borges\IEEEauthorrefmark{1}, Joel Ferreira\IEEEauthorrefmark{2}, Jorge Cruz\IEEEauthorrefmark{3}}
\IEEEauthorblockA{\textit{Departamento de Engenharia Informática}} \\
\textit{Instituto Superior de Engenharia do Porto}\\
Porto, Portugal \\
\IEEEauthorrefmark{1} 1100719@isep.ipp.pt\\
\IEEEauthorrefmark{2} 1191843@isep.ipp.pt\\
\IEEEauthorrefmark{3} 1221715@isep.ipp.pt\\
}


\maketitle

\begin{abstract}
Este artigo tem como objetivo a aplicação de algoritmos de aprendizagem automática na exploração de dados e respetiva comparação usando os testes estatísticos mais adequados. A temática incide sobre os níveis de poluição e seus impactos em diversos países europeus, no âmbito da disciplina de Análise de Dados em Informática. 

Foram aplicados modelos de regressão e classificação para prever mortes prematuras e distinguir doenças respiratórias. Os modelos foram avaliados com métricas estatísticas e comparados entre si.
\end{abstract}

\begin{IEEEkeywords}
poluição, saúde, regressão linear, classificação, árvores de decisão, K-vizinhos-mais-próximos, redes neuronais, SVM.
\end{IEEEkeywords}

\section{Introdução}

Este artigo começa por fazer uma introdução aos conceitos teóricos relevantes para a execução do trabalho e que foram abordados na disciplina de ANADI, \textbf{nomeadamente distribuição de dados, testes, correlações, regressões e previsões. }

De seguida, na ótica dos dados do problema - a poluição, são descritos os métodos e resultados obtidos em cada problema proposto. 

Por último, são apresentadas as conclusões do  trabalho.

Foi utilizado o \textit{python} para tratamento e processamento dos dados.

\section{Introdução Teórica}

Nesta secção serão introduzidos os conceitos teóricos sobre os diferentes algoritmos e modelos desenvolvidos na resolução deste trabalho. 

\subsection{Regressão}

\subsubsection{Regressão linear}

%\paragraph{}

A regressão linear é uma técnica estatística usada para modelar a relação entre uma variável dependente e uma ou mais variáveis independentes. Quando há apenas uma variável explicativa, o modelo é denominado \textbf{regressão linear simples}, sendo representado pela equação:

\begin{equation}
	Y = \beta_0 + \beta_1 X + \varepsilon
\end{equation}

onde \( Y \) é a variável que tentamos prever, denominada variável dependente. \( X \) é a variável independente (ou preditora), \( \beta_0 \) e \( \beta_1 \) são os coeficientes do modelo, e \( \varepsilon \) representa o erro aleatório. \cite{madureira2024aed}

\subsubsection{Regressão linear múltipla}
A regressão linear múltipla é uma extensão da regressão linear simples, na qual há mais de uma variável independente. A equação do modelo assume a forma:

\begin{equation}
	Y = \beta_0 + \beta_1 X_1 + \beta_2 X_2 + \dots + \beta_n X_n + \varepsilon
\end{equation}

Para se poder aplicar a regressão linear múltipla é necessário que exista uma relação linear entre a variável objetivo (Y) e as variáveis preditoras, os resíduos da regressão devem seguir uma distribuição normal e não deve existir multicolineariadade.\cite{madureira2024aed}

\subsection{Métricas de avaliação de modelos de regressão}

As métricas MAE, MSE, RMSE e R$^2$ são utilizadas principalmente para avaliar as taxas de erro de previsão e o desempenho do modelo na análise de regressão.

\medskip
\subsubsection{Mean Absolute Error - MAE}
Erro absoluto médio, é a soma das diferenças absolutas entre as previsões e os valores reais, dividindo pelo número total de pontos de dados.


\begin{equation}
	MAE = \frac{1}{n} {\sum_{i=1}^{n} |y_i - \hat{y_i}|}
	 \label{MAEeq}
\end{equation}

\medskip
\subsubsection{Mean Squared Error - MSE}
Erro quadrático médio, representa a diferença entre os valores originais e os valores previstos extraídos através do quadrado da diferença média do conjunto de dados.

\medskip
\subsubsection{Root Mean Squared Error - RMSE}
Mede a magnitude média do erro, tomando a raiz quadrada da média das diferenças quadráticas entre a previsão ($\hat{y_i}$) e a observação efetiva ($y_i$).


\begin{equation}
	RMSE = \sqrt{\frac{1}{n} {\sum_{i=1}^{n} (y_i - \hat{y_i})^2}}
	\label{RMSEeq}
\end{equation}

O RMSE é uma boa medida de exatidão, mas apenas para comparar erros de previsão de diferentes modelos ou configurações de modelos para uma determinada variável e não entre variáveis, uma vez que é dependente da escala. 

\medskip
\subsubsection{R$^2$ - Coeficiente de Determinação}

Representa o coeficiente de determinação dos valores em comparação com os valores originais. O valor de 0 a 1 é interpretado como percentagem. Quanto mais elevado for o valor, melhor é o modelo.\cite{madureira2024cv} 


\subsection{Árvores de Decisão}

Uma árvore de decisão,  \figurename~\ref{fig:Decision_Trees_example},  consiste num conjunto de nós de decisão, ligados por ramos, que se estendem para baixo a partir do nó raiz até terminarem em nós folha. 

Começando no nó raiz, que por convenção é colocado no topo do diagrama de árvore de decisão, as variáveis são testadas nos nós de decisão, sendo que cada resultado possível resulta num ramo. Cada ramo conduz então a outro nó de decisão ou a um nó folha terminal. 

A aprendizagem em árvore de decisão é um método de aproximação de uma função-alvo de valor discreto representada numa árvore de decisão. \cite{madureira2024dt}

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{Decision_Trees_example}
	\caption{Exemplo de árvore de decisão. \cite{madureira2024dt}}
	\label{fig:Decision_Trees_example}
\end{figure}

\subsubsection{Árvore de Decisão - Regressão}

As árvores de regressão são utilizados para prever variáveis-alvo contínuas, como o preço de uma casa ou o número de clientes que visitarão uma loja num determinado dia. Para fazer uma previsão, o regressor da árvore de decisão percorre a árvore desde o nó raiz até ao nó folha que corresponde às caraterísticas do novo ponto de dados. O valor previsto é então o valor médio da variável alvo para todos os pontos de dados no nó folha. \cite{ohekar_what_2023}

\medskip
\subsubsection{Árvore de Decisão - Classificação}

Os classificadores de árvores de decisão são utilizados para prever variáveis-alvo categóricas, como, por exemplo, se uma mensagem de correio eletrónico é ou não spam ou se um cliente vai ou não desistir. Para efetuar uma previsão, o classificador de árvore de decisão percorre a árvore desde o nó raiz até ao nó folha que corresponde às caraterísticas do novo ponto de dados. A classe prevista é então a classe com a maioria dos pontos de dados no nó folha. \cite{ohekar_what_2023}

\subsection{Cross-Validation}

A validação cruzada (Cross-Validation) é um método estatístico de avaliação e comparação de algoritmos de aprendizagem, dividindo os dados em dois segmentos: um utilizado para treinar um modelo e o outro utilizado para validar o modelo. Na validação cruzada típica, os conjuntos de treino e validação devem cruzar-se em rondas sucessivas, de modo a que cada ponto de dados tenha uma hipótese de ser validado. \cite{refaeilzadeh_cross-validation_2009}

\medskip
\subsubsection{Hold Out}

Esta abordagem consiste em dividir aleatoriamente os dados em dois conjuntos: um conjunto é utilizado para treinar o modelo e o outro conjunto é utilizado para testar o modelo. O processo funciona da seguinte forma: 
\begin{itemize}
	\item Construir (treinar) o modelo no conjunto de dados de treino; 
	\item Aplicar o modelo ao conjunto de dados de teste para prever o resultado de novas observações não vistas; 
	\item Quantificar o erro de previsão como a diferença média quadrática entre os valores de resultados observados e previstos. \cite{madureira2024cv}
\end{itemize}

\medskip
\subsubsection{K-Fold Cross-Validation}

O método de validação cruzada \textit{k-fold} avalia o desempenho do modelo em diferentes subconjuntos dos dados de treino e, em seguida, calcula a taxa média de erro de previsão. O algoritmo é o seguinte:
\begin{enumerate}
	\item Dividir aleatoriamente o conjunto de dados em \textit{k} subconjuntos (ou \textit{k-fold}) (por exemplo, 5 subconjuntos);
	\item Reservar um subconjunto e treinar o modelo em todos os outros subconjuntos;
	\item Testar o modelo no subconjunto reservado e registar o erro de previsão;
	\item Repetir este processo até que cada um dos \textit{k} subconjuntos tenha servido como conjunto de teste; 
	\item Calcular a média dos \textit{k} erros registados. Este é o chamado erro de validação cruzada, que serve de métrica de desempenho para o modelo. 
\end{enumerate}

A validação cruzada \textit{K-fold} (CV) é um método robusto para estimar a exatidão de um modelo. \cite{madureira2024cv}

\subsection{Redes Neuronais}

Uma rede neuronal, \figurename~\ref{fig:nn}, consiste numa rede de neurónios artificiais ou nós, em camadas, com alimentação direta e completamente ligada:

\begin{itemize}
	\item A natureza \textit{feedforward} da rede restringe-a uma única direção de fluxo e não permite ciclos. 
	\item A maioria das redes é constituída por três camadas: uma camada de entrada, uma camada oculta e uma camada de saída; 
	\begin{itemize}
		\item Pode haver mais de uma camada oculta, embora a maioria das redes contenha apenas uma, o que é suficiente para a maioria das finalidades.
	\end{itemize}
	
	  
	\item  A rede neuronal está completamente ligada, o que significa que cada nó de uma determinada camada está ligado a todos os nós das camadas adjacentes, mas não a outros nós da mesma camada:
	\begin{itemize}
		\item Cada conexão entre nós tem um peso (por exemplo, $w_{11}$) associado.
		\item  Na inicialização, estes pesos são atribuídos aleatoriamente a valores entre 0 e 1. \cite{madureira2024nn}
	\end{itemize}
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{NN}
	\caption{Exemplo de rede neuronal.}
	\label{fig:nn}
\end{figure}



\subsection{Support Vector Machines - SVM}

Uma máquina de vetores de suporte (SVM) é um algoritmo de aprendizagem automática supervisionada utilizado tanto para a classificação como para a regressão. Embora também se fale de problemas de regressão, é mais adequado para a classificação. O principal objetivo do algoritmo SVM é encontrar o hiperplano ideal num espaço N-dimensional que possa separar os pontos de dados em diferentes classes no espaço de caraterísticas, \figurename~\ref{fig:svm}. O hiperplano tenta que a margem entre os pontos mais próximos das diferentes classes seja a máxima possível. A dimensão do hiperplano depende do número de caraterísticas. Se o número de caraterísticas de entrada for dois, então o hiperplano é apenas uma linha. Se o número de caraterísticas de entrada for três, então o hiperplano torna-se num plano 2-D. \cite{madureira2024svm}

Terminologia:

\begin{itemize}
	\item \textbf{Hiperplano}: Um limite de decisão que separa diferentes classes no espaço de caraterísticas e é representado pela equação $wx + b = 0$ na classificação linear.
	
	\item \textbf{Vetores de suporte}: Os pontos de dados mais próximos do hiperplano, cruciais para determinar o hiperplano e a margem no SVM.
	
	\item \textbf{Margem}: A distância entre o hiperplano e os vetores de suporte. O objetivo do SVM é maximizar esta margem para obter um melhor desempenho de classificação.
	
	\item \textbf{Kernel}: Uma função que mapeia os dados para um espaço de dimensão superior, permitindo que o SVM lide com dados não linearmente separáveis. \cite{madureira2024svm}
\end{itemize}

\begin{figure}
	\centering
	\includegraphics[width=0.7\linewidth]{svm}
	\caption{Hiperplano, vetores de suporte e margem - SVM.}
	\label{fig:svm}
\end{figure}


\subsection{kNN - K-Vizinhos Mais Próximos}


O algoritmo do vizinho mais próximo (\textit{Nearest Neighbour}) classifica uma instância de dados com base nos seus vizinhos. A classe de uma instância de dados determinada pelo algoritmo dos k-vizinhos mais próximos é a classe com maior representação entre os k-vizinhos mais próximos. 

Os algoritmos do vizinho mais próximo estão entre os algoritmos de aprendizagem automática supervisionada mais “simples” e têm sido bem estudados no domínio do reconhecimento de padrões. 

O algoritmo do k-vizinho mais próximo é usado em projetos de classificação como referência de desempenho preditivo quando se está a tentar desenvolver modelos mais sofisticados. O kNN funciona utilizando a proximidade e a votação por maioria para efetuar previsões. \cite{madureira2024knn}

\section{Métodos e Resultados Obtidos}

\subsection{Análise Exploratória de Dados}
\medskip
\subsubsection{\textbf{Exercício 4.1.1}}

Neste exercício era pretendida a construção de um gráfico onde fosse possível verificar os níveis médios do poluente O$_3$ nas diversas regiões de Portugal. Era também requisito identificar a região com nível de O$_3$ mais elevado. Foram então importados os dados onde constava essa informação (ficheiro AIRPOL$\_$data).  

Para uma melhor visualização dos dados e para utilizarmos apenas os dados necessários, filtramos os mesmos. Assim, foram selecionados apenas os dados correspondentes a Portugal e cujo poluente em questão seja O$_3$. Verificamos a existência de alguns dados duplicados, o que nos levou à eliminação dos mesmos de modo a limpar o \textit{dataset}.
 
O gráfico obtido pode ser observado na \figurename~\ref{fig:nivelmedioo3}. É possível então verificar que todas as regiões apresentam um nível médio de O$_3$ situado entre os 80 e os 102.4 µg/m$^3$. A região com o maior valor médio de poluente é PT16H com um valor de 102.4 µg/m$^3$.


\medskip
\subsubsection{\textbf{Exercício 4.1.2}}

Pretendia-se a construção de um gráfico para comparação das distribuições dos níveis médios de PM2.5 em Portugal, Espanha, França e Itália. 

Inicialmente, os dados foram importados e filtrados. Como tal, foram selecionados apenas os dados correspondentes aos países mencionados anteriormente e cujo poluente em questão fosse PM2.5. Verificamos a existência de alguns dados duplicados, o que nos levou à eliminação dos mesmos de modo a limpar o dataset.

O gráfico obtido pode ser observado na \figurename~\ref{fig:niveismediospm25}. É possível então concluir o seguinte:

- Itália é o país que apresenta os valores mais elevados de PM2.5. Apresenta \textit{outliers} e uma grande dispersão de dados.

- Portugal e França apresentam níveis mais baixos de concentração de PM2.5. Estes dois países também apresentam a menor dispersão. França, apresenta um número de outliers mais elevado do que Portugal.

- Espanha, encontra-se entre os grupos de países mencionados anteriormente. A sua dispersão é superior à de Portugal e França.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{Niveis_medios_pm25}
	\caption{Distribuição dos níveis médios de PM2.5 por País}
	\label{fig:niveismediospm25}
\end{figure}

\medskip
\subsubsection{\textbf{Exercício 4.1.3}}

O objetivo deste exercício consiste na construção de um gráfico para comparação do número de mortes prematuras entre Portugal, Espanha, França e Itália. 

Os dados foram importados e filtrados. Como tal, foram selecionados apenas os dados correspondentes aos países mencionados. Para melhor visualização do dataframe, selecionamos apenas as colunas correspondentes ao país e ao valor de mortes prematuras. 

O gráfico obtido pode ser observado na \figurename~\ref{fig:mortesprematuras}. É possível então concluir o seguinte:

- A média de mortes prematuras tende a seguir valores baixos, embora sejam visíveis \textit{outliers}.

- Itália destaca-se pelo país com os números mais extremos de mortes prematuras.

- Portugal é o país que apresenta menor dispersão e valores menores de mortes prematuras.


\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{mortes_prematuras}
	\caption{Distribuição do número de mortes prematuras por País}
	\label{fig:mortesprematuras}
\end{figure}


\medskip
\subsubsection{\textbf{Exercício 4.1.4}}

Neste exercício era pretendida a construção de uma tabela que indicasse os valores da média, quartis, desvio padrão, assimetria e \textit{Kurtosis} relativa ao número de mortes prematuras associadas a Stroke para os seguintes países: Espanha, França, Itália e Grécia. Foram então importados os dados onde constava essa informação (ficheiro AIRPOLdata). 
 
Para uma melhor visualização dos dados e para utilizarmos apenas os dados necessários, filtramos os mesmos. Assim, foram selecionados apenas os dados correspondentes aos países mencionados e cujas mortes prematuras estivessem associadas a AVC (Stroke). 

Da tabela apresentada na figura \figurename~\ref{fig:valoresestatisticos}, é possível concluir o seguinte:

- O valor da média varia entre os diferentes países. É notório que Itália regista o maior número de mortes prematuras por AVC. França regista a menor média.

- Relativamente aos quartis, Itália apresenta os valores mais elevados para os mesmos, reforçando a tendência para os valores elevados. Esta medida ajuda a entender a dispersão dos dados.

- Itália apresenta também o desvio-padrão mais elevado, o que prova mais uma vez a sua grande disperão de dados. França apresenta o menor desvio-padrão e consequente menor dispersão.

- O coeficiente de assimetria é positivo. Isto indica que a distribuição tem uma cauda longa à direita. Logo, os países registam valores elevados de mortes prematuras por AVC. França e Itália apresentam os valores mais altos, o que indica que apresentam os outliers mais elevados.

- Os países registam uma Kurtosis elevada. Isto indica que há valores extremos a influenciar os dados. França e Itália reforçam a sua grande presença de \textit{outliers}.



\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{ValoresEstatísticosAVC}
	\caption{Valores da média, quartis, desvio padrão, assimetria e kurtosis, do número de mortes prematuras associado a AVC}
	\label{fig:valoresestatisticos}
\end{figure}


\subsection{Inferência Estatistica}
\medskip
\subsubsection{\textbf{Exercício 4.2.1}}

Neste exercício é necessário selecionar uma amostra aleatória de 50 registos dos níveis médios de poluição em Portugal e analisar a sua distribuição.

Filtrou-se os dados apenas para Portugal, realizou-se uma amostragem aleatória de 50 registos, calculou-se estatísticas descritivas e gerou-se um gráfico de barras da \figurename~\ref{fig:polportugal}.

A região mais poluída é a PT119 com um valor médio de poluição de 24,82 $\mu$g/m$^3$.

\begin{figure}
	\centering
	\includegraphics[width=0.9\linewidth]{pol_portugal.png}
	\caption{Distribuição dos níveis de poluição por região em Portugal}
	\label{fig:polportugal}
\end{figure}

\medskip
\subsubsection{\textbf{Exercício 4.2.2}}

Nesta questão vamos testar se o valor médio de poluição em Portugal é inferior ao da Albânia.

Selecionaram-se amostras independentes de 50 registos para cada país, verificou-se a normalidade usando o teste de \textit{Shapiro-Wilk} e a  homogeneidade de variâncias recorrendo ao teste de \textit{Levene}. 

Aplicou-se o teste \textit{t-Student} unilateral ($H_{0}: \mu_{\text{Portugal}} \geq \mu_{\text{Albânia}}$ vs $H_{1}: \mu_{\text{Portugal}} < \mu_{\text{Albânia}}$)

	\begin{table}[H]
		\centering
		\caption{Resultados dos testes estatísticos}
		\begin{tabular}{lcc}
			\toprule
			Teste & Estatística & p-valor \\
			\midrule
mer			Shapiro-Wilk (PT) & 0.2743 & 0.000 \\
			Shapiro-Wilk (AL) & 0.3545 & 0.000 \\
			Levene & 0.4467 & 0.5055 \\
			Teste t & -1.1860 & 0.1192 \\
			\bottomrule
		\end{tabular}
	\end{table}

Como p\textless0,05, rejeita-se $H_{0}$, concluindo-se que a poluição em Portugal é significativamente inferior à da Albânia, para um grau de confiança de 5\%.
\medskip
\subsubsection{\textbf{Exercício 4.2.3}}

Nesta alínea vamos verificar se há diferenças significativas nos níveis de poluição entre Espanha e França, para isso extraíram-se duas amostras independentes de 20 registos cada.

Testou-se a normalidade usando o teste de \textit{Shapiro-Wilk}, cujo resultado mostrou que os dados não seguem uma distribuição normal.

Aplicou-se, então, o teste não paramétrico \textit{Mann-Whitney-U}.

	\begin{table}[H]
		\centering
		\caption{Resultados dos testes estatísticos}
		\begin{tabular}{lcc}
			\toprule
			Teste & Estatística & p-valor \\
			\midrule
			Shapiro-Wilk (ES) & 0.5459 & 0.0000 \\
			Shapiro-Wilk (FR) & 0.3241 & 0.0000 \\
			Mann-Whitney U & 222.5000 & 0.5514 \\
			\bottomrule
		\end{tabular}
	\end{table}

Como p \textgreater 0.05, não há evidência de diferença significativa entre os dois países. 
\medskip
\subsubsection{\textbf{Exercício 4.2.4}}

	
\subsection{Classificação}\label{AA}

\subsubsection{\textbf{Exercício 4.3.1}}

Neste exercício iremos considerar os países das quatro regiões previamente definidas: \textit{Western Europe}, \textit{Eastern Europe}, \textit{Southern Europe} e \textit{Northen Europe}.

Derivando um novo atributo denominado \textit{RespDisease}, que separa as doenças em respiratórias e não-respiratórias. Na \figurename~\ref{fig:grafico_doenca_respir}, podemos observar a distribuição dos valores deste atributo, com 6270 doenças identificadas como não-respiratórias e 4180 como respiratórias.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{grafico_doenca_respir}
	\caption{Distribuição de valores entre doença Respiratória e Não-Respiratória.}
	\label{fig:grafico_doenca_respir}
\end{figure}


\medskip

\subsubsection{\textbf{Exercício 4.3.2}}

Usando o método \textit{k-fold cross validation} desenvolvemos modelos de previsão de \textit{RespDisease} usando os seguintes métodos:

\medskip

\paragraph{Árvore de Decisão}

Começamos por definir os dados de entrada (X), que contêm os valores das colunas \textit{Affected Population}, \textit{Populated Area[km2]}, \textit{Air Pollution Average[ug/m3]} e \textit{Value}  e a variável objetivo (y) - \textit{RespDisease}.

De seguida, o \textit{dataset} é dividido na proporção 70-30 para treino e teste, com opção estratificada que garante que a proporção das classes se mantém balanceada entre treino e teste.

Passamos à aplicação do método de \textit{cross-validation}, escolhendo \textit{k = 10 folds}. Este irá armazenar a exatidão de cada \textit{fold} (\textit{k}).

Depois deste passo, treina-se o modelo final com todos os dados de treino e avalia-se no conjunto de teste separado inicialmente. Para isso, a função \textit{DecisionTreeClassifier - DTC} é utilizada, com critério de entropia. Na \figurename~\ref{fig:arvoreDecisaoCM} podemos visualizar a matriz de confusão resultante.

Para otimizar os parâmetros do modelo vamos tentar perceber qual o nível de profundidade que gera um melhor desempenho, iterando-a de 1 a 10, no algoritmo DTC e aplicando a validação cruzada.

Tomando o valor máximo da exatidão entre os diferentes níveis, verifica-se que o valor é máximo para o nível 10 de profundidade.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.8\linewidth]{arvoreDecisaoCM}
	\caption{Matriz de Confusão do modelo final.}
	\label{fig:arvoreDecisaoCM}
\end{figure}


\begin{table}[ht]
	\centering
	\caption{Exatidão da árvore de decisão por profundidade}
	\begin{tabular}{|c|c|}
		\hline
		\textbf{Profundidade da Árvore} & \textbf{Exatidão} \\
		\hline
		1  & 0.697 \\
		2  & 0.731 \\
		3  & 0.746 \\
		4  & 0.764 \\
		5  & 0.775 \\
		6  & 0.786 \\
		7  & 0.797 \\
		8  & 0.803 \\
		9  & 0.812 \\
		10 & 0.817 \\
		\hline
	\end{tabular}
	\label{tab:acc_tree_depth}
\end{table}

\medskip

\paragraph{Rede Neuronal}

Iniciamos a abordagem de forma análoga ao problema anterior, contudo, desta vez, fazemos a codificação da variável objetivo recorrendo ao \textit{LabelEncoder}, que lhe atribui valores binários (0 e 1).

Depois da separação dos dados em treino e teste, é feita a sua normalização recorrendo ao \textit{MinMaxScaler}, uma vez que as variáveis preditoras têm valores de magnitude muito distantes.

Definiram-se 2 configurações possíveis para a rede neuronal - uma com 50 neurónios na \textit{hidden layer} e a segunda com duas camadas - 100 e 50 na mesma \textit{layer}. Em comum, estas configurações têm a função ativação (\textit{tanh}), parâmetro \textit{alpha} (0,01), \textit{solver} (\textit{lbfgs}) e numero máximo de iterações ($max\_iter = 500$).

Outros parâmetros foram testados como o \textit{solver} "adam" mas obtiveram-se resultados inferiores de exatidão.

Entre estas duas configurações, a segunda (100,50) revelou-se um pouco melhor a nível de performance. 

\medskip

\paragraph{SVM}

O método de SVM, ao contrário da rede neuronal, necessita dos dados normalizados com o \textit{StandardScaler}. 

Para este algoritmo foi utilizado o método SVC - \textit{Support Vector Classification}, com parâmetros C = 10 e C = 100. e usando o \textit{Kernel rbf}.

Na \figurename~\ref{fig:arvoreDecisaoCM} podemos visualizar a comparação entre os dois modelos, em que C=100 obtém uma ligeira vantagem.

\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{svm_compare}
	\caption{Comparação entre resultados de SVM para C=10 e C=100.}
	\label{fig:svm_compare}
\end{figure}


\medskip

\paragraph{K-vizinhos-mais-próximos - kNN}

Neste algoritmo, a normalização dos dados é necessária, para isso, utilizámos o \textit{MinMaxScaler}, uma vez que estamos a falar de distância entre pontos para a kNN.

O \textit{KNeighborsClassifier} foi utilizado, testando entre 1 e 49, num passo de 2 (1,3,5...49). De todas as iterações, foi encontrada a que tem maior exatidão para k=5, visivel na \figurename~\ref{fig:kNN_exatidao_vs_k}.


\begin{figure}[h]
	\centering
	\includegraphics[width=0.9\linewidth]{kNN_exatidao_vs_k}
	\caption{kNN - Valores de exatidão em função de número de vizinhos \textit{k}.}
	\label{fig:kNN_exatidao_vs_k}
\end{figure}

\medskip

\subsubsection{\textbf{Exercício 4.3.3}}

Para cada modelo da questão anterior obtemos os seguintes valores médios e desvio padrão de Accuracy, Sensitivity, Specificity e F1:

\begin{table}[h]
	\centering
	\scriptsize
	\caption{Desempenho dos Modelos de Classificação}
	\begin{tabular}{|l|c|c|c|c|}
		\hline
		\textbf{Métrica} & \textbf{Decision Tree} & \textbf{NN (100,50)} & \textbf{SVM (C=100)} & \textbf{KNN} \\
		\hline
		Accuracy    & 0.784 ± 0.017   & 0.815 ± 0.013 & 0.823 ± 0.011 & 0.614 ± 0.029 \\
		Sensitivity & 0.775 ± 0.031   & 0.660 ± 0.031 & 0.629 ± 0.028 & 0.507 ± 0.026 \\
		Specificity & 0.775 ± 0.010   & 0.920 ± 0.010 & 0.952 ± 0.008 & 0.686 ± 0.059 \\
		F1 Score    & 0.775 ± 0.019   & 0.741 ± 0.019 & 0.739 ± 0.020 & 0.513 ± 0.017 \\
		\hline
	\end{tabular}
\end{table}


\medskip

\subsubsection{\textbf{Exercício 4.3.4}}

À luz dos resultados obtidos na questão anterior, percebemos que os modelos de SVM e NN têm a melhor \textit{accuracy} (exatidão), por isso, verificámos se existe uma diferença significativa no desempenho entre os dois, para um nível de significância de 5\% recorrendo ao teste \textit{t-stat}.

Como o\textit{ p-value} é inferior a 0,05, concluímos que há diferenças estatisticamente significativas entre os dois modelos.


\medskip

\subsubsection{\textbf{Exercício 4.3.5}}

A análise detalhada dos modelos revelou que o SVM com parâmetro \( C=100 \) apresenta o melhor desempenho global. Os principais pontos fortes incluem a maior \textit{accuracy} (82{,}3\%) entre todos os modelos, excelente \textit{specificity} (95{,}2\%) — o que indica menor número de falsos positivos — e baixa variabilidade, o que demonstra consistência nos resultados. Contudo, a principal limitação é a \textit{sensitivity} mais baixa (62{,}9\%), o que pode levar à perda de casos positivos.

A rede neural com arquitetura (100,50) foi a segunda melhor opção, alcançando uma \textit{accuracy} de 81{,}5\%, o melhor \textit{F1-score} (74{,}1\%), indicando bom equilíbrio entre precisão e sensibilidade, e uma \textit{specificity} elevada (91{,}9\%). No entanto, a \textit{sensitivity} foi inferior à da Árvore de Decisão.

A Árvore de Decisão destacou-se por apresentar a maior sensitivity (77{,}5\%), sendo a mais indicada em contextos onde é fundamental não deixar de identificar ocorrências relevantes. O modelo também apresentou equilíbrio geral entre as métricas, mas a \textit{accuracy} foi inferior à dos modelos SVM e NN.

Por fim, o modelo KNN demonstrou o pior desempenho geral, com a menor \textit{accuracy} (61{,}4\%), alta variabilidade entre os \textit{folds} e o \textit{F1-score} mais baixo (51{,}3\%), indicando um desempenho inferior em todos os aspetos avaliados.

\section*{Conclusões}

Da análise exploratória de dados, foi possível verificar que todas as regiões portuguesas apresentam um nível médio de O3 situado entre os 80 e os 102.4 ug/m3. A região com o maior valor médio de poluente é PT16H com um valor de 102.4 µg/m3.

Relativamente à concentração do poluente PM2.5 foram analisados os países Portugal, Espanha, França e Itália. Itália é o país que apresenta os valores mais elevados, sendo observados outliers e uma grande dispersão de dados. Portugal e França apresentam níveis mais baixos de concentração de PM2.5.

A média de mortes permaturas tende a seguir valores baixos, embora se tenham verificado outliers. Itália destaca-se pelo país com os números mais extremos de mortes permaturas. Portugal é o país que apresenta menor dispersão e valores menores de mortes permaturas.

Relativamente às mortes associadas a AVC, Itália volta a registar o maior número de mortes permaturas em relação aos países analisados (França, Grécia, Itália e Espanha).

Da inferência estatistica podemos concluir que a Albânia tem níveis de poluição significativamente mais altos que Portugal, Espanha e França.

Portugal apresenta menor poluição que a Albânia, mas sem diferença significativa face a Espanha e França.

Não existe correlação significativa entre os níveis de poluição médios de PM2.5 para asma e doença isquémica do coração entres Portugal, Espanha, França ou Itália.

Para o problema do poluente PM2.5 na Alemanha, os dados não cumprem os pressupostos necessários para se efetuar inferência estatística e, embora o modelo obtido tenha um coeficiente de determinação de 76,8\%, as previsões de mortes ficam completamente desfasadas da realidade.

\begin{thebibliography}{00}
\bibitem{madureira2024aed}
Madureira, A., \& Matos, J. (2024). *Aulas T - Linear Regression and Tree Regression*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{madureira2024cv}
Madureira, A. (2024). *Aulas T - Cross Validation*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{moore2017}
Moore, D. S., McCabe, G. P., \& Craig, B. A. (2017). *Introduction to the Practice of Statistics* (9th ed.). New York: W. H. Freeman.
\bibitem{madureira2024}
Madureira, A., \& Matos, J. (2024). *Aulas T - Testes de Correlação*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{zar2005}
Zar, J. H. (2005). *Spearman Rank Correlation*. In Biostatistical Analysis (5th ed., pp. 383-387). Pearson Prentice Hall.
\bibitem{madureira2024adi}
Madureira, A. (2024). *Aulas T - Introduction to Machine Learning*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{madureira2024dt}
Madureira, A. (2024). *Aulas T - Decision Trees*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{ohekar_what_2023}
A.~Ohekar, ``What is the difference between a Decision Tree Classifier and a Decision Tree Regressor?,'' \emph{Medium}, Sep. 26, 2023. [Online]. Available: https://medium.com/@aaryanohekar277/what-is-the-difference-between-a-decision-tree-classifier-and-a-decision-tree-regressor-36641bd6559c [Accessed: Jun. 7, 2025].
\bibitem{refaeilzadeh_cross-validation_2009}
P.~Refaeilzadeh, L.~Tang, and H.~Liu, ``Cross-Validation,'' in \emph{Encyclopedia of Database Systems}, Springer, Boston, MA, 2009, pp. 532--538.
\bibitem{madureira2024nn}
Madureira, A. (2024). *Aulas T - Neural Networks*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{madureira2024svm}
Madureira, A. (2024). *Aulas T - Support Vector Machines*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{madureira2024knn}
Madureira, A. (2024). *Aulas T - kNN Algorithm*. Instituto Superior de Engenharia do Porto (ISEP). Ano letivo 2024/2025.
\bibitem{montgomery2021} 
Montgomery, D. C., Peck, E. A., \& Vining, G. G. (2021). 
\textit{Introduction to Linear Regression Analysis} (6ª ed.). Wiley.




\end{thebibliography}

\end{document}
